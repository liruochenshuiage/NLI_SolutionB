{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11366408,"sourceType":"datasetVersion","datasetId":7114777},{"sourceId":11366680,"sourceType":"datasetVersion","datasetId":7114992},{"sourceId":332414,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":278643,"modelId":299546}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Layer\n\n# Attention Layer\nclass Attention(Layer):\n    def __init__(self, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(\n            name='attention_weight',\n            shape=(input_shape[-1], 1),\n            initializer='glorot_uniform',\n            trainable=True\n        )\n        super(Attention, self).build(input_shape)\n\n    def call(self, inputs):\n        score = tf.matmul(inputs, self.W)\n        score = tf.nn.softmax(score, axis=1)\n        context_vector = inputs * score\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n        return context_vector","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:44:28.227265Z","iopub.execute_input":"2025-04-11T11:44:28.227801Z","iopub.status.idle":"2025-04-11T11:44:42.976693Z","shell.execute_reply.started":"2025-04-11T11:44:28.227782Z","shell.execute_reply":"2025-04-11T11:44:42.975878Z"}},"outputs":[{"name":"stderr","text":"2025-04-11 11:44:31.550777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744371871.740643      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744371871.797126      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model('/kaggle/input/bilstm/tensorflow2/default/1/bilstm_best_model.h5', custom_objects={'Attention': Attention})\nprint(\"model load successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:44:42.977539Z","iopub.execute_input":"2025-04-11T11:44:42.978013Z","iopub.status.idle":"2025-04-11T11:44:45.945154Z","shell.execute_reply.started":"2025-04-11T11:44:42.977992Z","shell.execute_reply":"2025-04-11T11:44:45.944515Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1744371884.014458      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"model load successfully\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pickle\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# load tokenizer\nwith open('/kaggle/input/tokenizer/tokenizer.pkl', 'rb') as f:\n    tokenizer = pickle.load(f)\n\n# get test data\ntest_df = pd.read_csv('/kaggle/input/nli-test/test.csv')\ntest_texts_raw = test_df['premise'] + ' [SEP] ' + test_df['hypothesis']\n\n# clean\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z0-9\\s.,!?]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ntest_texts = [clean_text(t) for t in test_texts_raw]\nX_test_seq = tokenizer.texts_to_sequences(test_texts)\nX_test = pad_sequences(X_test_seq, maxlen=70, padding='post', truncating='post')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:45:17.525775Z","iopub.execute_input":"2025-04-11T11:45:17.526085Z","iopub.status.idle":"2025-04-11T11:45:17.722136Z","shell.execute_reply.started":"2025-04-11T11:45:17.526062Z","shell.execute_reply":"2025-04-11T11:45:17.721593Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\npred_probs = model.predict(X_test)\n\npred_labels = np.argmax(pred_probs, axis=1)\n\n# save to CSV\npd.DataFrame(pred_labels, columns=[\"prediction\"]).to_csv('prediction666.csv', index=False)\n\nprint(\"✅ prediction.csv with header saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T11:54:43.790021Z","iopub.execute_input":"2025-04-11T11:54:43.790330Z","iopub.status.idle":"2025-04-11T11:54:44.705944Z","shell.execute_reply.started":"2025-04-11T11:54:43.790304Z","shell.execute_reply":"2025-04-11T11:54:44.705120Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n✅ prediction.csv with header saved!\n","output_type":"stream"}],"execution_count":8}]}